#!/bin/bash

mydir=$(realpath $(dirname $0))
root=$mydir/..
if [ -z $gazelle ]; then
    export gazelle=$root/components/gazelle_plugin
fi
if [ -z $SPARK_HOME ]; then
    export SPARK_HOME=$root/components/spark
fi

if [ -z $GAZELLE_JNI_HOME ]; then
    export GAZELLE_JNI_HOME=$root
fi

version="1.2.0-snapshot"
gazelle_jni_jar=${GAZELLE_JNI_HOME}/jvm/target/gazelle-jni-jvm-${version}-jar-with-dependencies.jar
#datasource_jar=${GAZELLE_JNI_HOME}/xiphos-spark-integration/xiphos-datasource/target/xiphos-datasource-1.2.0-snapshot-jar-with-dependencies.jar       
datasource_jar=${GAZELLE_JNI_HOME}/xiphos-spark-integration/xiphos-datasource/target/xiphos-datasource-1.2.0-snapshot.jar       


${SPARK_HOME}/bin/spark-shell \
        --verbose \
        --master "local[1]" \
        --driver-memory 10G \
        --conf spark.driver.extraClassPath=${gazelle_jni_jar}:${datasource_jar} \
        --conf spark.executor.extraClassPath=${gazelle_jni_jar}:${datasource_jar} \
        --conf spark.driver.cores=1 \
        --conf spark.executor.instances=12 \
        --conf spark.executor.cores=6 \
        --conf spark.executor.memory=20G \
        --conf spark.memory.offHeap.size=80G \
        --conf spark.task.cpus=1 \
        --conf spark.locality.wait=0s \
        --conf spark.sql.shuffle.partitions=72 \
        --conf spark.plugins=com.intel.oap.GazellePlugin \
        --conf spark.sql.sources.useV1SourceList=avro \
        --jars ${gazelle_jni_jar},${datasource_jar} $*
# Use the following switches to disable gazelle-jni
#        --conf spark.oap.sql.columnar.batchscan=false \
#        --conf spark.oap.sql.columnar.hashagg=false \
#        --conf spark.oap.sql.columnar.projfilter=false \

